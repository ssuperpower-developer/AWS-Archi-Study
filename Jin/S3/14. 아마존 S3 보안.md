
## S3 암호화 개요
4가지 방법

1. Server Side Encryption SSE
	1. SSE-S3 (SSE with Amazon S3 managed keys): 버킷과 객체에 대해서 기본값으로 활성화 되어 있음 (디폴트)
	2. SSE-KMS (SSE with KMS keys stored in AWS KMS): KMS 키를 이용해서 암호화 키를 관리 
	3. SSE-C(SSE with Customer-Providerd Keys): 클라이언트가 제공한 키를 사용. 
2. Client Side Encryption CSE
  
Amazon S3의 객체 암호화 방식은 크게 **서버 측 암호화(SSE)** 와 **클라이언트 측 암호화**로 나뉩니다.

---

### **1. 서버 측 암호화 (SSE)**

Amazon S3가 데이터 업로드 시 자동으로 암호화하고 저장합니다.

- **SSE-S3**
    - AWS가 처리하고 관리하고 소유한 키 사용        
    - 사용자할 수는 엑세스할 수 없음 
    - 기본값으로 활성화됨
    - 헤더: `"x-amz-server-side-encryption":"AES256"`
    - 암호화 방식: AES-256
    - 새로운 버킷과 새로운 객체에 대해서 이게 디폴트임
    - 작동방식
	    1. 저 헤더를 달고서 파일을 업로드하면 s3가 보유한 키랑 object(올린 파일)을 매핑함.
	    2. 키랑 object를 혼합해서 암호화함. 
	    3. 암호화한게 버킷에 저장됨
	    ![[스크린샷 2025-05-10 오후 5.00.17.png]]
        
- **SSE-KMS**
    - AWS와 S3 서비스가 보유한 키에 의존하지 않음
    - KMS 서비스(키 관리 서비스)를 이용해서 사용자가 직접 자신의 키를 생성하고 관리
    - 로그는 CloudTrail에 기록됨    
    - 헤더: `"x-amz-server-side-encryption":"aws:kms"`
    - 단점: KMS API 호출 제한 존재
	- 작동방식
		1. 객체 업로드 
		2. 헤더 `"x-amz-server-side-encryption":"aws:kms"` 헤더 안에서 사용하려는 KMS키 지정 
		3. Amazon S3에 있는 객체 + 외부에서 온(내가 올린) KMS키 = 두개를 혼합해서 암호화 -> 암호화된 파일이 S3 버킷으로 감 
		4. 파일을 읽기 위해서는 객체에 엑세스 + KMS 키에도 엑세스 할 수 있어야함. (보안 수준 강화)
			![[스크린샷 2025-05-10 오후 5.02.09.png]]
	
	- 제한 사항 
		- S3에 파일 업로드/다운로드시에 **KMS API**(예: `GenerateDataKey`, `Decrypt`)를 호출하게 됩니다.
		- 이 **API 호출은 KMS의 초당 호출 제한(쿼터)**에 포함됩니다.
		- **KMS 쿼터는 기본적으로 리전마다 초당 5,000 ~ 30,000건** 수준입니다.
		    - 이 제한은 콘솔에서 요청하면 늘릴 수 있음.
		- 그런데 만약 **S3 처리량이 매우 높고, 모든 파일이 SSE-KMS로 암호화되어 있다면**,
		    - **KMS 쿼터를 초과해서 요청이 스로틀(throttle)** 될 수 있습니다.
		    - 즉, 요청이 지연되거나 거부될 수 있습니다.
		- 이건 **스로틀링(throttling, 제한)**의 대표적인 사례 중 하나입니다.
- **SSE-C**
    - 사용자가 제공한 키 사용
    - 키는 AWS에 저장되지 않음 (전송 후 폐기됨)
    - 키를 AWS에 전송하기 때문에 HTTPS로 전송 필수
    - 헤더에 키를 전달
    - 암호화는 서버 측에서 수행되지만 키는 직접 제공
	![[스크린샷 2025-05-10 오후 5.03.46.png]]
### **2. 클라이언트 측 암호화**  CSE
- 라이브러리 쓰면 쉽게 할 수 있음
- 클라이언트가 직접 데이터를 암호화한 후 S3에 업로드
- 복호화도 클라이언트에서 직접 수행
- 암호화 키 및 사이클 완전 관리 필요
    ![[스크린샷 2025-05-10 오후 5.05.11.png]]

### **3. 전송 중 암호화 (SSL/TLS)
 S3 버킷에 기본적으로 두가지 엔드포인트가 있음
- HTTP endpoint: 암호화 x
- **HTTPS endpoint**: 암호화 0
	- s3에 대한 요청을 할때 사용을 100% 권장
	- 근데 거의 모든 클라이언트가 HTTPS 엔드포인트를 사용함
- 강제할 수 있는 방법
	- 버킷 정책을 통해 암호화되지 않은 전송(HTTP) 차단 / HTTPS만 허용하도록 설정
    ```json
    "Condition": {
      "Bool": {
        "aws:SecureTransport": "false"
      }
    }
    ```
    
---
## DSSE-KMS에 대한 안내

  X
```
다음 강의에서 실습을 할 때, 이제부터 [2023년 6월에 출시](https://aws.amazon.com/blogs/aws/new-amazon-s3-dual-layer-server-side-encryption-with-keys-stored-in-aws-key-management-service-dsse-kms/)된 새로운 암호화 옵션인 DSSE-KMS를 사용할 수 있다는 것을 알게 될 것입니다.

  

**DSSE-KMS는 "KMS를 기반으로 한 이중 암호화"일 뿐입니다.**

  

시험에 출제되지 않는 한 이 과정에서는 가르치지 않을 것입니다.

시험에 옵션으로 표시되는 경우 알려주시면 강좌를 업데이트하겠습니다.

  

즐거운 학습 되세요!
```
----
## S3 암호화 실습

### 1.  버킷 생성 및 암호화 설정

- `demo-encryption-stephane-v2`라는 S3 버킷을 생성.
- 버킷 버저닝(Versioning) **활성화**.
- **기본값 암호화** 설정에서 **SSE-S3** 선택.
    - SSE-S3: S3가 자체적으로 관리하는 키를 사용하여 암호화.

### 2. 객체 업로드 및 암호화 확인

- `coffee.jpg` 업로드.
- 업로드 후 객체의 **암호화 방식이 SSE-S3**임을 확인.
- **암호화 방식 편집** 시, 객체의 **새 버전이 생성됨** (버저닝이 켜져 있어서).

### 3. 암호화 방식 변경 실습
- 해당 객체에 대해 **기본값 암호화 무시**.
- **SSE-KMS** 선택:
    - KMS 키로 암호화 (직접 키 지정 가능).
    - **기본 키(aws/s3)** 사용 → **추가 비용 없음**.        
    - **사용자 정의 KMS 키** 생성 시 매월 비용 발생.
    
### 4. 다른 파일 업로드
- 다른 파일 `beach.jpg` 업로드 시 **암호화 설정 오버라이드도 가능**
	- SSE-S3, SSE-KMS, DSSE-KMS 중 선택 가능.
- SSE-KMS를 기본값으로 설정 시, **버킷 키 옵션** 활성화 가능:
    - **KMS 호출 수 감소**로 **비용 절감 효과**.
- SSE-S3 선택 시 해당 옵션 없음.
- **SSE-C**는 콘솔에서 설정 불가 (CLI만 가능).
	- **클라이언트 측 암호화**는 S3가 관여하지 않으며, 사용자가 직접 암호화/복호화 처리해야 함.


---

## S3 기본 암호화

- **기본값 암호화(Default Encryption)**:
    - ==모든 S3 버킷은 기본적으로 **SSE-S3** 암호화가 적용됨.==
    - 사용자는 이를 **SSE-KMS** 또는 **SSE-C**로 변경 가능
    - 새로 업로드되는 객체에 자동으로 적용됨.
- **버킷 정책(Bucket Policy)**:
    - **암호화 강제 가능**.
    - 예: `PutObject` 요청에 `aws:kms` 또는 `SSE-C` 헤더가 없으면 **요청 거부**.
    - **객체 업로드 시 적절한 암호화가 설정되었는지 검사**함.
- **정리**:
    - 기본값 암호화는 자동 적용
    - 버킷 정책은 **암호화 준수 여부를 강제**하는 용도.
    - ==**버킷 정책은 기본값 암호화보다 우선적으로 평가**됨.==
        

## S3 CORS

### 개요
CORS (Cross-Origin Resource Sharing)
- **CORS란?**  
    웹 브라우저의 **보안 메커니즘**으로, 현재 오리진(Origin) 외의 **다른 오리진에 대한 요청을 허용하거나 거부**할 수 있도록 **제어**하는 기능.
    
- **오리진이란?**  
    `프로토콜 + 도메인 + 포트`의 조합.  
    예: `https://www.example.com:443`  
    이 조합이 다르면 **다른 오리진**으로 간주됨.
	 - 예) http://example.com/app1 이랑 http://example.com/app2 랑은 같은 오리진
	 - 예) http://www.example.com 이랑 http://other.example/com 은 다른 오리진
	- 예시)
		- 웹 브라우저로 한 웹사이트를 방문함. 
		- 요청 중에 하나가 다른 웹사이트에 요청을 보내야함.
		- 이때, 다른 오리진이 CORS 헤더를 사용해서 요청을 허용하지 않는한, 해당 요청은 불가함
		- 이게 `Access-Control-Allow-Origin`임
- **CORS 작동 방식**
    1. 브라우저가 다른 오리진에 요청을 시도함.
    2. 브라우저는 **사전 요청(preflight request)**을 전송 (OPTIONS 요청).
    3. 대상 서버가 `Access-Control-Allow-Origin` 헤더로 **요청을 허용**해야 실제 요청이 가능.
    4. 그렇지 않으면 요청 **차단**.
![[스크린샷 2025-05-10 오후 5.24.19.png]]
- **Amazon S3에서의 CORS 적용**
    - S3 버킷에 정적 웹사이트 호스팅 설정 시, **교차 오리진 요청을 허용하려면 CORS 규칙**을 설정해야 함.
    - 예: 이미지 리소스가 다른 버킷에 있을 경우, 해당 버킷에 CORS 허용 설정이 없으면 **이미지 로드 실패**.
        
- **시험 포인트**
    - `Access-Control-Allow-Origin` 헤더의 역할.
    - `*`(와일드카드)을 사용하여 모든 오리진 허용 가능.
    - **브라우저 기반 요청**만 CORS 영향을 받음 (서버-서버는 해당 없음).
        


### 실습

-  실습 목표
	- **같은 오리진에서는 fetch가 정상 작동**하는 것을 확인하고,
	- **다른 오리진에서 fetch 요청 시 CORS 에러 발생**, 이를 해결하기 위해 CORS 설정을 추가합니다.
    

-  실습 절차
	1. **`index.html` 파일 수정**
	    - 주석 처리된 HTML과 JavaScript 코드를 활성화.
	    - `fetch`로 `extra-page.html`을 불러오고, 이미지 아래에 표시.
	2. **같은 오리진 내 테스트**
	    - 같은 S3 버킷에 `index.html`과 `extra-page.html` 업로드.
	    - 웹 브라우저에서 두 파일 정상 표시됨 (`fetch` 성공).
	3. **다른 오리진에서 fetch 요청 시도**
	    - 새로운 S3 버킷 생성 (리전 다르게 설정하여 다른 오리진으로 인식).
	    - 이 버킷에도 `extra-page.html` 업로드.
	    - 기존 `index.html`에서 `fetch` URL을 새 버킷의 경로로 수정.
	4. **CORS 에러 발생 확인**
	    - 브라우저 개발자 도구 콘솔에서 "CORS 헤더 누락" 오류 확인.
	5. **CORS 설정 추가**
	    - 새 버킷의 Permissions > CORS configuration에 JSON 설정 추가.
	    - `AllowedOrigins`에 원래 버킷의 URL 입력.
	6. **CORS 성공 확인**
	    - 웹 페이지 새로고침 시 오류 없이 다른 버킷의 HTML 내용 정상 표시.
	    - 네트워크 탭에서 응답 헤더에 CORS 관련 필드 존재 확인 (`Access-Control-Allow-Origin`, `Access-Control-Allow-Methods` 등).
        
>- 결론 
	- 같은 오리진에서는 `fetch`가 기본적으로 작동함.
	- 다른 오리진에서 요청하려면 **CORS 설정을 명시적으로 추가해야** 함.
	- 시험에 자주 등장하므로 실습을 통해 이해해 두는 것이 좋음.
	    


## S3 MFA Delete

### 개요
- **MFA(Multi-Factor Authentication)**: Google Authenticator 같은 앱이나 MFA 하드웨어 장치를 통해 생성된 코드를 입력해야 중요한 작업을 수행할 수 있도록 하는 보안 기능입니다.
    ![[Pasted image 20250507202430.png]]
- **사용 목적**:
    - 객체 버전의 **영구 삭제** 시
    - 버킷에서 **버저닝 중단** 시  
        위와 같은 **파괴적인 작업**에 대해 추가 보호를 제공합니다.
        
- **불필요한 경우**: 버저닝 활성화, 삭제된 버전 나열 등은 위험도가 낮아 MFA가 필요 없습니다.
    
- MFA delete 사용**조건**:
    - **버저닝이 활성화된 버킷**에서만 사용 가능
    - **루트 계정만** MFA Delete 설정 가능
        
- **한줄 정리**: ==실수로 인한 데이터 손실을 막는 **강력한 보호 수단**==
    



## S3 엑세스 로그 
### 개요
- **정의**: S3 버킷에 대한 **모든 요청(성공/실패 포함)** 을 기록하는 기능
- **용도**: 보안 및 **감사 추적**을 위해 사용되며, Amazon Athena 같은 도구로 분석할 수 있음
- **로그 저장 위치**: 로그는 **다른 S3 버킷**에 저장되며, 해당 **로깅 버킷은 같은 AWS 리전에 있어야** 함
        
- **작동 방식**:
    - S3 버킷 설정에서 **액세스 로그 활성화**
    - 이후 모든 요청 정보가 로그 파일로 기록됨
        
- **참고**: 로그 형식은 AWS 공식 문서에서 확인 가능 
	- https://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html
- **주의사항**:
    - ==**로깅 버킷과 소스 버킷이 같으면 안 됨!**==  never ever set!!!
        → 그렇지 않으면 **로깅 루프** 발생 → 로그가 계속 생성됨 → **비용 폭증**
	![[스크린샷 2025-05-10 오후 5.50.50.png]]
### 실습
1. **로깅 버킷 생성**
    - 이름: `s3-access-logs-stephane-v3`
    - 이 버킷은 **로그 저장용 버킷**으로 사용됨
        
2. **로깅 활성화 대상 버킷 선택**
    - S3 콘솔에서 원하는 버킷 선택
    - **[속성(Properties)] → [서버 액세스 로깅]으로 이동**
    - **편집 → 로깅 활성화**
        
3. **로깅 설정**
    - **목적지 버킷**: `s3-access-logs-stephane-v3`
    - **지역**: `eu-west-1`
    - **접두사(Prefix)**: 생략 가능
    - **로그 키 형식**: 기본값 사용
        
4. **버킷 정책은 자동으로 업데이트됨**
    
5. **이벤트 발생해서 로깅되는지 확인**
    - 예시: `beach.jpg` 같은 파일 업로드로 S3 활동 발생
    - 로그는 **몇 분~몇 시간 후에 생성**
    - 로깅 버킷 내 객체 확인 가능
    - 각 로그 파일에는 **요청 시간, API 호출, 요청자, 성공/실패 여부 등**이 포함됨
        
6. **결론**
    - S3 액세스 로그를 통해 **보안 감사 및 활동 추적 가능**
    - 분석 도구와 함께 사용하면 유용함



---

## S3 사전 서명된 URL (pre-signed URLs)


![[스크린샷 2025-05-10 오후 9.03.55.png]]
1. S3 객체에 대한 임시 접근 권한을 부여하는 URL
	- S3 콘솔, CLI, SDK를 통해 생성 가능

2. **만료 시간**
    - **S3 콘솔**: 최대 **12시간**
    - **CLI**: 최대 **168시간 (7일)**
    
3. **권한 상속**
    - URL을 생성한 **사용자의 권한(예: GET, PUT)**을 **URL 사용자가 그대로 사용**        
    - URL 자체가 미리 서명된 것이기 때문

4. **대표적인 사용 사례**
    - **프라이빗 버킷**의 객체를 외부 사용자에게 **일시적으로 공유**
    - **프리미엄 콘텐츠 다운로드** 허용 (예: 유료 사용자)
    - **임시 업로드 허용**: 외부 사용자가 S3에 파일 업로드 (PUT) 가능
    - **보안 유지**: 버킷은 비공개 상태 유지, 공개로 설정할 필요 없음
        
5. **작동 방식**
    - 미리 서명된 URL에는 요청에 필요한 **자격 증명, 요청 방법, 만료 시간 등이 포함됨**
    - 지정된 시간 내에만 사용 가능, 만료 후에는 **액세스 불가**
        
6. **장점**
    - **URL 만료시간을 정함으로써 보안성 유지 + 유연한 공유** 가능
    - **정밀한 제어**: 어떤 파일, 어떤 동작(GET/PUT), 얼마나 오랫동안

---

## S3 잠금 정책 및 Glacier Vault Lock (볼트 잠금)
###  **S3 Glacier 볼트 잠금**
- 스토리지 클래스 중 Glacier의 옵션 중 하나
- **목적**: WORM(Write Once, Read Many) 모델 구현
- **특징**
    - **볼트 잠금 정책**을 설정하고 **잠그면 변경/삭제 불가**
    - 일단 잠기면 **관리자 및 AWS 서비스조차 수정/삭제 불가**
    - **규정 준수 및 장기 보존**에 적합
    - 단순하고 강력한 보안 옵션


### **S3 객체 잠금**
- **전제 조건**: 버킷의 **버저닝 활성화** 필요
- **대상**: 버킷 단위가 아니라 개별 객체 단위로 WORM 적용 가능
- 특정 객체를 특정 시간 동안 삭제되는걸 차단 할 수 있음 
- **보존 모드
    1. **규정 준수 모드 (Compliance Mode)**
	    -  **S3 Glacier 볼트 잠금**이랑 비슷
        - 누구도 삭제나 수정 불가
        - 보존 기간 변경 불가 → 가장 **엄격**
    2. **거버넌스 모드 (Governance Mode)**
        - 일반 사용자는 수정/삭제 불가
        - **관리자 권한**이 있으면 변경 가능
        - 더 **유연한 제어** 가능
	- **보존 기간 설정 필수** (단, 연장은 가능)
    
- **법적 보존 (Legal Hold)**
    - **보존 기간 무관**하게 버킷 내 객체를 무기한 보호
    - `s3:PutObjectLegalHold` 권한 필요
    - 법적 조사 등 특별한 아주 중요한 상황에서 사용


### 📌 시험 대비 핵심 정리

| 구분       | 규정 준수 모드 | 거버넌스 모드  | 법적 보존         |
| -------- | -------- | -------- | ------------- |
| 삭제 가능 여부 | 절대 불가    | 관리자만 가능  | 무기한 보호        |
| 보존 기간 변경 | 불가       | 관리자만 가능  | 무관            |
| 사용 예     | 법적 규제 준수 | 일반 조직 보안 | 재판 등 법적 이슈 대응 |


  ---

## S3 엑세스 포인트

하나의 S3 버킷에 대해 다양한 사용자나 애플리케이션이 서로 다른 방식으로 접근할 수 있도록 
보안을 세분화하고 쉽게 관리할 수 있게 해주는 기능

![[스크린샷 2025-05-10 오후 9.17.16.png]]
- 예를 들어, `/finance`, `/sales` 같은 접두어에 따라 각각 **Finance**, **Sales**, **Analytics** 액세스 포인트를 만들 수 있으며, 각 엑세스 포인트는 고유한 정책을 통해 특정 데이터에 대한 **읽기/쓰기 권한**을 관리할 수 있습니다.
- 액세스 포인트는 **S3 버킷 정책**과 별도로 존재하며, **IAM 권한**과 함께 사용되어 **보안 관리의 단순화와 확장성**을 제공합니다.
- 액세스 포인트는 고유의 **DNS 이름**을 가지며, 이를 통해 애플리케이션이 S3 버킷에 연결됩니다.
    





----
## S3 오브젝트 람다
- **S3 액세스 포인트의 활용
	- S3 객체를 가져오기 직전에 수정**할 수 있도록 해줍니다.
![[스크린샷 2025-05-10 오후 9.23.29.png]]
예를 들어
- **분석기 애플리케이션**은 원본 객체에서 PII 데이터를 제거한 버전을 원할 수 있고,
- **마케팅 애플리케이션**은 고객 데이터가 **보강된 객체**를 원할 수 있습니다.
    

이럴 때, 각 애플리케이션마다 S3 버킷을 새로 만들 필요 없이:
1. **S3 액세스 포인트에 액세스
2. 람다 함수 호출
3. 람다함수가 요청 시점에 객체를 수정/삭제하거나 변환(예: PII 제거, JSON 변환, 워터마크 삽입)
    
결과적으로 하나의 S3 버킷으로 다양한 애플리케이션 요구에 맞는 **맞춤형 객체 응답**을 제공할 수 있게 됩니다.

활용 사례:
- 민감 정보 제거 (PII)
- 데이터 포맷 변환 (XML → JSON)
- 이미지 리사이징 또는 워터마크 삽입
    
