# AWS 미들웨어: 효율적인 어플리케이션 통합을 위한 핵심 개념 🔄

분산 시스템에서 어플리케이션이 효율적으로 협업하기 위한 방법과 패턴에 대한 설명이다.

디커플링 = > **“각 컴포넌트(부분)가 서로 독립적으로 동작할 수 있도록 연결을 느슨하게 만드는 것”**

## 1. 어플리케이션 통합의 필요성 🌐

현대 시스템은 대부분 마이크로서비스 아키텍처를 기반으로 하며, 여러 독립적인 서비스로 구성된다. 이러한 분산 환경에서는:

- 서비스 간에 데이터와 정보를 공유해야 함
- 다양한 기능을 담당하는 애플리케이션들이 협업해야 함
- 서로 다른 개발 팀이 만든 서비스들이 함께 작동해야 함

이렇게 분리된 서비스들이 효과적으로 통신하기 위해서는 적절한 통합 방식이 필요하다.

## 2. 어플리케이션 통합의 두 가지 주요 패턴 📊

어플리케이션 간 통신은 크게 두 가지 패턴으로 나눌 수 있다:

### 2.1 동기식 통합 (Synchronous Integration)

![[스크린샷 2025-05-10 오후 2.07.36.png]]
**특징**:

- 서비스 A가 서비스 B를 직접 호출
- 요청-응답 모델로 작동
- 서비스 A는 서비스 B의 응답을 기다림

**예시 시나리오**: 구매 서비스가 상품 판매 후 즉시 배송 서비스에 연락해 배송 프로세스를 시작하고, 배송 서비스의 확인을 기다립니다.

**장점**:

- 간단한 구현
- 즉각적인 응답 확인
- 직관적인 흐름

**단점**:

- 높은 결합도
- 장애 전파 위험
- 확장성 제한

### 2.2 비동기식/이벤트 기반 통합 (Asynchronous/Event-Driven Integration)

![[스크린샷 2025-05-10 오후 2.08.25.png]]

**특징**:

- 서비스 간 직접 연결 없음
- 중간에 미들웨어(대기열, 이벤트 버스 등)를 통한 통신
- 이벤트 생성자와 소비자의 분리

**예시 시나리오**: 구매 서비스가 상품 판매 이벤트를 메시지 대기열에 발행하고 계속 자기 할일을 한다. 배송 서비스는 독립적으로 대기열을 폴링하여 새로운 배송 요청을 처리한다.

**장점**:

- 낮은 결합도
- 장애 격리
- 뛰어난 확장성
- 부하 관리 용이

**단점**:

- 더 복잡한 아키텍처
- 즉각적인 응답 없음
- 디버깅 어려움

## 3. 동기식 통합의 문제점 ⚠️

동기식 통합은 간단하지만 여러 문제를 야기할 수 있다:

### 3.1 확장성 문제

한 서비스의 갑작스러운 트래픽 증가가 다른 서비스에 직접적인 영향을 미친다:

- **사례**: 갑자기 1,000개의 동영상이 업로드되면, 인코딩 서비스가 감당하지 못하고 중단될 수 있음
- **결과**: 전체 시스템 성능 저하 또는 장애

### 3.2 단일 장애점

서비스 간 직접 연결로 인해 한 서비스의 장애가 전체 시스템에 영향을 준다:

- **사례**: 결제 서비스가 다운되면 주문 처리 흐름 전체가 중단됨
- **결과**: 연쇄적인 서비스 중단 및 사용자 경험 저하

### 3.3 리소스 관리 어려움

트래픽 피크 시 리소스 할당과 관리가 복잡해진다:

- **사례**: 특정 시간에 주문량이 급증하면 배송 서비스에 즉각적인 부하 발생
- **결과**: 리소스 낭비 또는 부족 현상

## 4. AWS의 비동기 통합 서비스 제품군 🛠️

AWS는 비동기 통합을 지원하는 세 가지 주요 서비스를 제공한다:

### 4.1 Amazon SQS (Simple Queue Service)

**핵심 개념**:

- 메시지 대기열 서비스
- 서비스 간 메시지 전달 및 버퍼 역할
- 분산 시스템에서 컴포넌트 분리에 이상적

**사용 사례**:

- 주문 처리 시스템
- 작업 큐
- 비동기 처리 요청

### 4.2 Amazon SNS (Simple Notification Service)

**핵심 개념**:

- 발행-구독(Pub/Sub) 메시징 서비스
- 하나의 메시지를 여러 구독자에게 전달
- 팬아웃 패턴 구현에 최적화

**사용 사례**:

- 이벤트 알림
- 모바일 푸시 알림
- 이메일 및 SMS 발송

### 4.3 Amazon Kinesis

**핵심 개념**:

- 실시간 스트리밍 데이터 처리
- 대량 데이터 수집 및 분석
- 고성능 실시간 처리에 최적화

**사용 사례**:

- 로그 및 이벤트 데이터 수집
- 실시간 분석
- IoT 데이터 스트림 처리

## 5. 비동기 통합의 주요 이점 🌟

### 5.1 서비스 분리 및 독립적 확장

각 서비스를 독립적으로 확장할 수 있어 리소스 효율성이 높아진다:

- 트래픽이 많은 서비스만 추가 리소스 할당 가능
- 각 서비스의 구체적인 요구 사항에 맞춰 개별 확장 가능

### 5.2 부하 관리 및 버퍼링

급격한 트래픽 증가에도 안정적인 처리가 가능하다:

- 갑작스러운 트래픽 급증을 미들웨어가 흡수
- 소비자 서비스는 자신의 처리 능력에 맞게 메시지 처리

### 5.3 장애 격리

한 서비스의 장애가 전체 시스템으로 전파되는 것을 방지한다:

- 메시지 생산자는 소비자의 상태와 무관하게 작동
- 한 서비스의 다운타임이 다른 서비스에 영향 최소화

### 5.4 유연한 시스템 진화

새로운 기능이나 서비스를 기존 시스템에 영향 없이 추가할 수 있다:

- 새 소비자 추가 시 기존 생산자 변경 불필요
- 점진적 시스템 업그레이드 가능


# Amazon SQS: 확장 가능한 메시지 대기열 서비스 📬

SQS는 애플리케이션 간 통신과 분리를 위한 핵심 서비스이다. 📚

## 1. SQS의 기본 개념 🔄
![[스크린샷 2025-05-10 오후 2.13.02.png]]
### 핵심 요소

- **대기열(Queue)**: 메시지를 저장하는 중앙 컴포넌트
- **생산자(Producer)**: 대기열에 메시지를 보내는 주체 (하나 또는 여러 개 가능)
- **소비자(Consumer)**: 대기열에서 메시지를 받아 처리하는 주체 (하나 또는 여러 개 가능)
- **메시지**: 처리해야 할 작업 정보 (최대 256KB)

### 작동 방식

1. 생산자가 `SendMessage` API를 통해 메시지를 대기열에 보냄
2. 메시지는 처리되기 전까지 대기열에 저장됨 (기본 4일, 최대 14일)
3. 소비자는 대기열을 폴링하여 메시지 존재 여부 확인
4. 메시지를 받으면 처리 후 `DeleteMessage` API로 삭제

## 2. SQS의 주요 특징 🌟

### 성능 및 확장성

- **무제한 처리량**: 초당 보낼 수 있는 메시지 수에 제한 없음
- **무제한 메시지 수**: 대기열에 저장할 수 있는 메시지 수에 제한 없음
- **낮은 지연 시간**: 게시 및 수신 시 약 10ms 이내의 응답 시간

### 메시지 처리 특성

- **최소 1회 전송**: 메시지는 최소 한 번은 전달됨 (중복 가능성 있음)
- **최선의 순서**: 메시지 순서가 항상 보장되지는 않음
- **메시지 크기**: 최대 256KB (더 큰 메시지는 S3에 저장 후 참조 권장)
- **메시지 수명**: 기본 4일, 최대 14일까지 설정 가능

## 3. 소비자 동작 방식 🔍

![[스크린샷 2025-05-10 오후 2.17.08.png]]
### 메시지 폴링

- 소비자는 대기열에 메시지가 있는지 주기적으로 확인
- 한 번에 최대 10개의 메시지 수신 가능
- 메시지 처리 후 반드시 삭제해야 함 (그렇지 않으면 다른 소비자가 볼 수 있음)

### 다중 소비자

![[스크린샷 2025-05-10 오후 2.17.43.png]]

- 여러 소비자가 동시에 같은 대기열에서 메시지 수신 가능
- 한 소비자가 메시지를 수신하면 일정 시간(가시성 제한 시간) 동안 다른 소비자에게 표시되지 않음
- 시간 내 처리하지 못하면 다른 소비자가 해당 메시지를 볼 수 있음

## 4. Auto Scaling과의 통합 📈

![[스크린샷 2025-05-10 오후 2.18.51.png]]
### 동적 소비자 확장

- 소비자를 Auto Scaling Group(ASG)과 통합 가능
- `ApproximateNumberOfMessages` CloudWatch 지표로 대기열 길이 모니터링
- 대기열 길이가 특정 임계값 초과 시 소비자 인스턴스 자동 확장

### 처리량 최적화

- 메시지 양이 증가하면 소비자도 자동으로 증가
- 메시지 양이 감소하면 불필요한 소비자 인스턴스 자동 축소
- 비용 최적화와 효율적인 처리 가능

## 5. 애플리케이션 분리 사용 사례 🧩

![[스크린샷 2025-05-10 오후 2.21.20.png]]
### 프론트엔드-백엔드 분리

- 프론트엔드: 사용자 요청 처리 및 메시지 대기열에 작업 요청 전송
- 백엔드: 대기열에서 메시지를 수신하여 무거운 처리 작업 수행
- 각 계층이 독립적으로 확장 가능

### 비디오 처리 예시

- **프론트엔드**: 사용자로부터 비디오 업로드 받음
- **SQS 대기열**: 처리 요청 메시지 저장
- **백엔드 처리**: GPU 인스턴스로 구성된 ASG가 비디오 처리
- 프론트엔드는 빠르게 응답하고, 백엔드는 비디오 처리에 집중

## 6. SQS 보안 🔒

### 데이터 보호

- **전송 중 암호화**: HTTPS API를 통한 기본 암호화
- **저장 데이터 암호화**: KMS 키를 사용한 서버 측 암호화
- **클라이언트 측 암호화**: 옵션으로 가능 (자체 구현 필요)

### 액세스 제어

- **IAM 정책**: SQS API 작업에 대한 권한 제어
- **SQS 액세스 정책**: S3 버킷 정책과 유사한 리소스 정책
    - 교차 계정 액세스 허용
    - 다른 AWS 서비스(SNS, S3 등)의 SQS 접근 허용

## 7. 주요 사용 시나리오 🎯

- 주문 처리 시스템: 주문 접수와 처리 분리
- 이미지/비디오 처리: 무거운 처리 작업 분리
- 이메일 전송 대기열: 사용자 알림 비동기 처리
- 작업 분배: 여러 워커에게 작업 균등 분배
- 부하 평준화: 트래픽 급증 시 버퍼 역할


# Amazon SQS 메시지 가시성 시간 초과 (Message Visibility Timeout) 📝

Amazon SQS의 핵심 개념 중 하나인 **메시지 가시성 시간 초과(Message Visibility Timeout)**에 대해 알아보자. 이 개념은 메시지의 중복 처리를 방지하고 안정적인 시스템을 구축하는 데 중요하다.

## 1. 메시지 가시성 시간 초과란? 🕒

메시지 가시성 시간 초과는 소비자가 메시지를 받은 후, 해당 메시지가 다른 소비자에게 보이지 않게 되는 시간 간격이다.

### 기본 작동 방식

1. 소비자가 `ReceiveMessage` API로 메시지를 수신
2. 수신된 메시지는 가시성 시간 초과 기간 동안 대기열에서 "숨겨짐"
3. 이 시간 내에 메시지가 삭제되지 않으면, 메시지는 다시 대기열에 표시됨
4. 다른 소비자가 같은 메시지를 다시 수신할 수 있게 됨

**기본값**: 30초 (0초에서 12시간 사이로 설정 가능)

## 2. 가시성 시간 초과의 중요성 🛡️

### 주요 목적

- **중복 처리 방지**: 한 소비자가 메시지를 처리하는 동안 다른 소비자가 동일한 메시지를 처리하지 않도록 함
- **처리 보장**: 메시지가 처리되지 않았을 경우(예: 소비자 충돌) 다시 대기열에 표시되어 다른 소비자가 처리할 수 있도록 함
- **리소스 효율성**: 여러 소비자가 같은 메시지에 동시에 작업하는 것을 방지하여 리소스 낭비 최소화

### 시나리오 예시

![[스크린샷 2025-05-10 오후 2.31.55.png]]
👨‍💻 **소비자 A**:

1. 메시지 수신 (30초 가시성 시간 시작)
2. 메시지 처리 시작
3. 처리 중 충돌 발생 (메시지 삭제 못함)

⏱️ **30초 후**:

- 메시지가 다시 대기열에 표시됨

👩‍💻 **소비자 B**:

1. 이제 같은 메시지를 볼 수 있음
2. 메시지 수신 및 처리
3. 성공적으로 처리 후 메시지 삭제

## 3. 가시성 시간 초과 관리 ⚙️

### 적절한 시간 설정의 중요성

- **너무 짧게 설정 (몇 초)**:
    - 소비자가 메시지를 처리하기 전에 시간 초과 발생
    - 여러 소비자가 동일한 메시지를 처리하게 됨 (중복 처리)
    - 시스템 리소스 낭비 및 잠재적 데이터 불일치 발생 가능
- **너무 길게 설정 (몇 시간)**:
    - 소비자가 충돌했을 때 메시지가 오랫동안 처리되지 않음
    - 시스템 처리량 감소
    - 메시지 처리 지연 증가

### `ChangeMessageVisibility` API

메시지 처리에 예상보다 더 많은 시간이 필요한 경우, 소비자는 이 API를 사용하여 가시성 시간 초과를 연장할 수 있다:

python

```python
# 예시 코드 (Python)
import boto3

sqs = boto3.client('sqs')

# 메시지 수신
response = sqs.receive_message(
    QueueUrl='https://sqs.region.amazonaws.com/account-id/queue-name',
    MaxNumberOfMessages=1
)

# 메시지 처리 시작...
# 처리 시간이 더 필요하다고 판단될 경우

# 가시성 시간 초과 연장 (예: 60초 추가)
if 'Messages' in response:
    receipt_handle = response['Messages'][0]['ReceiptHandle']
    sqs.change_message_visibility(
        QueueUrl='https://sqs.region.amazonaws.com/account-id/queue-name',
        ReceiptHandle=receipt_handle,
        VisibilityTimeout=60  # 새로운 가시성 시간 초과 값 (초)
    )
```

## 4. 실제 사용 시나리오와 모범 사례 🌟

### 시간 초과 설정 전략

- **애플리케이션 처리 시간 분석**: 메시지 처리에 걸리는 평균 및 최대 시간 측정
- **평균 처리 시간의 2-3배로 설정**: 처리 시간에 변동이 있을 경우 여유 확보
- **하트비트 구현**: 긴 처리 작업 중 주기적으로 `ChangeMessageVisibility` 호출

### 신뢰성 있는 메시지 처리 패턴

1. **점진적 가시성 확장**:
    - 초기에는 짧은 가시성 시간 설정
    - 처리 진행에 따라 `ChangeMessageVisibility`로 시간 점진적 연장
    - 예: 30초 → 60초 → 120초 → ...
2. **주기적 진행 상황 확인**:
    
    python
    
    ```python
    def process_message(message):
        # 처리 시작
        while not is_processing_complete():
            # 작업 진행...
            
            # 10초마다 가시성 갱신
            if time_since_last_extension > 10:
                extend_visibility(message, 60)  # 60초 추가
        
        # 처리 완료 후 메시지 삭제
        delete_message(message)
    ```
    
3. **멱등성 구현**:
    - 메시지가 여러 번 처리되더라도 시스템에 부작용이 없도록 설계
    - 고유 메시지 ID를 사용하여 이전에 처리된 메시지 추적

## 5. 실제 예시 분석 📊

콘솔 예시에서 본 시나리오를 분석해보자:

1. **첫 번째 소비자**:
    - "Hello World" 메시지 수신
    - 30초 가시성 시간 초과 시작
    - 이 기간 동안 두 번째 소비자는 메시지를 볼 수 없음
2. **가시성 시간 초과 경과**:
    - 첫 번째 소비자가 메시지를 삭제하지 않음
    - 메시지가 다시 대기열에 표시됨
    - 두 번째 소비자가 이제 동일한 메시지를 볼 수 있음
3. **수신 카운터 증가**:
    - 메시지가 두 번 수신됨 (수신 카운터 = 2)
    - 잠재적으로 동일한 메시지가 두 번 처리될 수 있음

## 6. 가시성 시간 초과 관련 문제 해결 🔧

### 일반적인 문제점

1. **메시지 중복 처리**:
    - **원인**: 가시성 시간 초과가 너무 짧게 설정됨
    - **해결책**: 시간 초과 값 증가 또는 `ChangeMessageVisibility` 사용
2. **메시지 처리 지연**:
    - **원인**: 가시성 시간 초과가 너무 길게 설정됨
    - **해결책**: 적절한 시간으로 조정, 소비자 오류 모니터링 강화
3. **데드레터 큐 활용**:
    - 반복적으로 실패하는 메시지를 격리하여 시스템 안정성 향상
    - 일정 횟수 이상 수신된 메시지는 자동으로 데드레터 큐로 이동


# Amazon SQS 롱 폴링 (Long Polling) 📥

## 1. 롱 폴링이란? 🕰️

롱 폴링은 소비자가 SQS 대기열에 메시지를 요청할 때, 메시지가 없는 경우 즉시 빈 응답을 반환하는 대신 **지정된 시간 동안 기다렸다가** 메시지가 도착하면 즉시 응답을 반환하는 방식이다.
![[스크린샷 2025-05-10 오후 3.41.31.png]]
### 기본 작동 방식

1. 소비자가 `ReceiveMessage` API를 호출하며 대기 시간 파라미터(`WaitTimeSeconds`) 지정
2. 대기열에 메시지가 없으면 API 연결이 유지되며 지정된 시간 동안 대기
3. 대기 시간 내에 메시지가 도착하면 즉시 소비자에게 전달
4. 대기 시간이 만료될 때까지 메시지가 도착하지 않으면 빈 응답 반환

**대기 시간 범위**: 1~20초 (최대 효율을 위해 20초 권장)

## 2. 롱 폴링의 주요 이점 🌟

### 2.1 API 호출 수 감소

- **비용 절감**: SQS API 호출 횟수 대폭 감소
- **예시**: 쇼트 폴링(1초 간격)은 시간당 3,600회 API 호출, 롱 폴링(20초)은 시간당 180회로 20배 감소

### 3.2 지연 시간 감소

- **즉각적인 처리**: 메시지 도착 즉시 소비자에게 전달
- **실시간성 향상**: 메시지 처리 시작 시간 단축

### 3.3 빈 응답 감소

- **리소스 효율성**: 빈 응답에 대한 처리 오버헤드 감소
- **네트워크 트래픽 감소**: 불필요한 통신 최소화

### 3.4 처리량 향상

- **효율적인 메시지 배치 처리**: 한 번의 폴링으로 최대 10개 메시지 수신 가능
- **일괄 처리 최적화**: 메시지 도착을 기다려 배치 처리 가능


# Amazon SQS FIFO 대기열: 순서와 정확성을 보장하는 메시징 시스템 🔄

## 1. FIFO 대기열이란? 📋

FIFO(First-In-First-Out) 대기열은 메시지가 대기열에 전송된 정확한 순서대로 처리되는 것을 보장하는 Amazon SQS의 대기열 유형이다.

### 1.1 FIFO vs 표준 대기열 비교

| 특성     | FIFO 대기열                   | 표준 대기열             |
| ------ | -------------------------- | ------------------ |
| 메시지 순서 | 엄격한 순서 보장                  | 최선의 노력 순서 (보장 없음)  |
| 메시지 전송 | 정확히 한 번 처리                 | 최소 한 번 처리 (중복 가능)  |
| 처리량    | 제한됨 (초당 300개, 배치 시 3,000개) | 무제한                |
| 사용 사례  | 순서가 중요한 트랜잭션 처리            | 높은 처리량이 필요한 분산 시스템 |
|        |                            |                    |

## 2. FIFO 대기열의 주요 특징 🌟

![[스크린샷 2025-05-10 오후 3.51.10.png]]

### 2.1 엄격한 메시지 순서 보장

FIFO 대기열은 메시지가 전송된 정확한 순서대로 배달되는 것을 보장한다:

- 생산자가 메시지 1→2→3→4 순서로 보내면
- 소비자는 항상 동일한 1→2→3→4 순서로 메시지를 수신
- 어떤 메시지도 순서에서 벗어나지 않음

### 2.2 정확히 한 번 처리

FIFO 대기열은 중복 제거 기능을 통해 동일한 메시지가 여러 번 처리되는 것을 방지합니다:

- **5분**의 중복 제거 간격 동안 동일 식별자(Id)를 가진 메시지는 한 번만 처리
- 시스템 오류나 네트워크 문제로 인한 중복 전송 방지
- 애플리케이션 수준의 멱등성 구현 없이도 정확히 한 번 처리 가능

### 2.3 제한된 처리량

순서 보장과 중복 제거를 위해 FIFO 대기열은 처리량에 제한이 있습니다:

- **표준 처리량**: 초당 최대 300개의 메시지
- **배치 처리량**: 초당 최대 3,000개의 메시지 (10개씩 배치 처리 시)

### 2.4 메시지 그룹 ID

FIFO 대기열에서는 메시지 그룹 ID를 사용하여 관련 메시지의 처리 순서를 제어할 수 있다:

- 같은 메시지 그룹 ID를 가진 메시지는 엄격히 순서대로 처리
- 서로 다른 메시지 그룹 ID를 가진 메시지는 **병렬 처리** 가능
- 메시지 그룹 ID는 FIFO 대기열에서 필수 속성

### 2.5 메시지 중복 제거 ID

중복 제거를 위해 각 메시지에 고유한 중복 제거 ID가 필요하다:

- 생산자가 제공하는 명시적 중복 제거 ID
- 콘텐츠 기반 중복 제거 (메시지 본문의 해시 사용)
- 5분의 중복 제거 간격 동안 유효

## 3. FIFO 대기열 생성 및 구성 ⚙️

### 3.1 대기열 이름 규칙

FIFO 대기열을 생성할 때는 특별한 이름 지정 규칙을 따라야 한다:

- 대기열 이름이 `.fifo` 접미사로 끝나야 함
- 예: `myQueue.fifo`, `orderProcessing.fifo`
- 이 접미사가 없으면 FIFO 대기열로 생성 불가

### 3.2 콘텐츠 기반 중복 제거

AWS 콘솔이나 API를 통해 콘텐츠 기반 중복 제거를 활성화할 수 있다:

- 활성화 시: 메시지 본문 해시를 기반으로 자동 중복 제거
- 비활성화 시: 각 메시지에 명시적 중복 제거 ID 제공 필요

### 3.3 주요 구성 옵션

FIFO 대기열 생성 시 고려해야 할 몇 가지 중요한 설정:

- **가시성 제한 시간**: 메시지가 처리 중일 때 다른 소비자에게 숨겨지는 시간
- **메시지 보존 기간**: 삭제되지 않은 메시지가 대기열에 보존되는 시간 (최대 14일)
- **배달 지연**: 메시지가 대기열에 추가된 후 소비자에게 표시될 때까지의 지연 시간
- **최대 메시지 크기**: 최대 256KB까지 설정 가능


# SQS와 Auto Scaling Group 연동: 효율적인 워크로드 처리 전략 🚀


## 1. SQS와 ASG 연동의 기본 원리 🔄

### 기본 아키텍처

- **SQS 대기열**: 메시지 버퍼 역할
- **ASG 내 EC2 인스턴스**: 대기열에서 메시지를 폴링하여 처리
- **CloudWatch**: 대기열 길이를 모니터링하고 ASG에 스케일링 트리거 제공

### 작동 방식
![[스크린샷 2025-05-10 오후 3.56.57.png]]
1. EC2 인스턴스는 SQS 대기열에서 메시지를 폴링
2. CloudWatch가 `ApproximateNumberOfMessages` 지표 모니터링
3. 지표가 임계값을 초과하면 경보 발생
4. 경보가 ASG의 스케일 아웃 액션 트리거
5. 새 EC2 인스턴스가 추가되어 처리량 증가
6. 대기열 크기가 감소하면 ASG 스케일 인 발생

## 2. CloudWatch 경보 설정 ⚠️

### 주요 지표

- **`ApproximateNumberOfMessages`**: 대기열에서 처리 대기 중인 메시지 수
- **`ApproximateAgeOfOldestMessage`**: 가장 오래된 메시지의 대기 시간

### 경보 구성 예시

- 대기열에 1,000개 이상 메시지가 있으면 스케일 아웃
- 대기열에 100개 미만 메시지가 있으면 스케일 인
- 5분 이상 조건이 유지될 때 액션 실행

## 3. 주요 활용 패턴: 데이터베이스 쓰기 버퍼링 💾
![[스크린샷 2025-05-10 오후 3.59.20.png]]
### 문제 상황 (SQS 안쓸 때)

- 대규모 판매 이벤트나 광고 캠페인으로 인한 트래픽 급증
- 데이터베이스(RDS, Aurora, DynamoDB 등)의 쓰기 용량 한계
- 일부 트랜잭션 유실 위험

### 해결 방안

1. ==애플리케이션이 DB에 직접 쓰지 않고 SQS 대기열에 메시지 전송==
2. SQS는 무제한 처리량으로 모든 요청 안전하게 저장
3. 별도의 ASG가 메시지를 처리하여 데이터베이스에 순차적으로 삽입
4. 데이터베이스 부하 분산 및 트랜잭션 유실 방지

### 이점

- 트랜잭션 유실 없음
- 데이터베이스 과부하 방지
- 처리 지연은 있지만 데이터 무결성 보장
- 비용 효율적인 리소스 사용

## 4. 애플리케이션 티어 분리 아키텍처 🏢

![[스크린샷 2025-05-10 오후 4.01.50.png]]
### 구성 요소

- **프론트엔드 티어**: 사용자 요청 처리, SQS에 메시지 게시
- **SQS 대기열**: 요청 버퍼링
- **백엔드 처리 티어**: SQS에서 메시지 수신, 실제 비즈니스 로직 처리

### 장점

- 프론트엔드가 빠르게 응답 가능(비동기 처리)
- 각 티어를 독립적으로 스케일링 가능
- 시스템 장애 발생 시 데이터 손실 방지
- 부하 변동에 효과적으로 대응

## 요약📌

1. **자동 스케일링 트리거**:
    - SQS 대기열 길이 기반 CloudWatch 경보 사용
    - `ApproximateNumberOfMessages` 지표 모니터링
2. **데이터베이스 쓰기 버퍼**:
    - 트래픽 급증 시 SQS를 버퍼로 활용
    - 모든 트랜잭션 안전하게 저장 후 순차적 처리
3. **애플리케이션 티어 분리**:
    - 프론트엔드와 백엔드 처리 분리
    - 비동기 처리로 사용자 경험 향상
4. **적용 시나리오**:
    - 갑작스러운 트래픽 급증 처리
    - 데이터베이스 부하 분산
    - 시스템 내결함성 향상

이 패턴은 AWS 시험에서 자주 등장하는 내용으로, 특히 부하 분산, 내결함성, 확장성 관련 문제에서 적절한 솔루션으로 제시된다. 분리, 급격한 로드 증가, 타임아웃 문제가 언급될 때 SQS와 ASG의 조합을 기억하자


# Amazon SNS: 확장 가능한 발행-구독 메시징 서비스 📢

## 1. SNS의 기본 개념 📋

SNS는 메시지 발행자(게시자)가 여러 구독자에게 메시지를 전송할 수 있는 발행-구독(Pub/Sub) 메시징 서비스이다.

### 핵심 구성 요소

- **주제(Topic)**: 메시지를 게시하고 구독하는 논리적 액세스 포인트
- **게시자(Publisher)**: 주제에 메시지를 전송하는 서비스나 애플리케이션
- **구독자(Subscriber)**: 주제의 메시지를 수신하는 엔드포인트
- **메시지(Message)**: 게시자가 구독자에게 전송하는 정보

## 2. 직접 통합 vs Pub/Sub 패턴 🔄

![[스크린샷 2025-05-10 오후 4.09.13.png]]
### 직접 통합(Direct Integration)

```
구매 서비스 → 이메일 알림
         → 사기 탐지 서비스
         → 배송 서비스
         → SQS 대기열
```

**단점**:

- 수신자 추가 시 코드 수정 필요
- 복잡한 의존성 관리
- 확장성 제한

### Pub/Sub 패턴

```
구매 서비스 → SNS 주제 → 이메일 알림
                    → 사기 탐지 서비스
                    → 배송 서비스
                    → SQS 대기열
```

**장점**:

- 느슨한 결합(Loose coupling)
- 새 구독자 추가가 쉬움
- 게시자는 구독자를 알 필요 없음
- 확장성이 뛰어남

## 3. SNS 주요 특징 🌟

### 용량 및 제한

- 주제별 최대 1,200만 이상의 구독자 가능
- 계정당 최대 10만 개의 주제 생성 가능 (요청 시 증가 가능)
- 메시지 크기 최대 256KB

### 구독 프로토콜

![[스크린샷 2025-05-10 오후 4.09.48.png]]

SNS는 다양한 엔드포인트 유형을 지원한다:

- **이메일**: 일반 텍스트 이메일로 알림 수신
- **이메일-JSON**: JSON 형식의 이메일로 알림 수신
- **SMS**: 문자 메시지로 알림 수신
- **HTTP/HTTPS**: 웹훅으로 알림 수신
- **SQS**: Amazon SQS 대기열로 알림 전송
- **Lambda**: AWS Lambda 함수 호출
- **모바일 푸시**: 모바일 앱에 알림 전송
- **Firehose**: Kinesis Data Firehose를 통해 데이터 스트리밍

## 4. SNS 통합 서비스 🔌

### 게시자로 작동하는 AWS 서비스

SNS로 알림을 보내는 주요 AWS 서비스:

- **CloudWatch**: 경보 상태 변경 시 알림
- **Auto Scaling Groups**: 확장/축소 이벤트 알림
- **CloudFormation**: 스택 상태 변경 알림
- **AWS Budgets**: 예산 임계값 초과 알림
- **S3**: 버킷 이벤트(생성, 삭제 등) 알림
- **DMS**: 데이터 마이그레이션 이벤트
- **Lambda**: 함수 실행 결과 알림
- **DynamoDB**: 스트림 이벤트
- **RDS**: 데이터베이스 이벤트 알림


## 5. SNS 보안 🔒

### 데이터 보호

- **전송 중 암호화**: HTTPS를 통한 기본 암호화
- **저장 데이터 암호화**: KMS 키를 사용한 서버 측 암호화
- **클라이언트 측 암호화**: 클라이언트에서 직접 구현 가능

### 액세스 제어

- **IAM 정책**: SNS API 액세스 제어
- **SNS 액세스 정책**: S3 버킷 정책과 유사
    - 교차 계정 액세스 허용
    - 다른 AWS 서비스의 SNS 주제 액세스 허용


Amazon SNS는 이벤트 기반 아키텍처 구축에 필수적인 서비스로, SQS와 함께 사용하면 확장성과 탄력성이 뛰어난 시스템을 구현할 수 있다. 특히 여러 시스템에 동일한 메시지를 동시에 전송해야 하는 경우에 SNS의 Pub/Sub 모델이 매우 유용하다. 


# SNS+SQS Fan Out 패턴

이 패턴은 하나의 메시지를 여러 시스템에 효율적으로 배포하는 강력한 아키텍처이다. 💻
## 1. Fan Out 패턴의 필요성 🔄

### 문제 상황

여러 SQS 대기열에 동일한 메시지를 개별적으로 전송할 때 발생하는 문제들:

- 애플리케이션 충돌 시 일부 대기열에만 메시지 전송
- 새로운 대기열 추가 시 코드 수정 필요
- 메시지 전송 실패에 대한 복원력 부족
- 유지보수 복잡성 증가


나 → A에게 메시지 전송  
나 → B에게 메시지 전송  
나 → C에게 메시지 전송

> 만약 중간에 휴대폰이 꺼지면? → B, C는 메시지 못 받음
> 새로운 친구 D가 생기면? → 코드를 수정해야 함

### 해결책: Fan Out 패턴

- SNS 토픽으로 한 번만 메시지를 전송
- 여러 SQS 대기열이 해당 토픽을 구독
- 모든 구독 대기열이 동일한 메시지를 수신

## 2. Fan Out 패턴의 기본 구성 📊

### 아키텍처 구성![[스크린샷 2025-05-10 오후 4.14.33.png]]


### 구현 필수 사항

- SQS 대기열 접근 정책 설정: SNS 토픽이 대기열에 메시지를 쓸 수 있도록 허용
- SNS 토픽에 SQS 대기열을 구독자로 등록

### 장점

- 완전한 결합 분리
- 데이터 손실 방지
- SQS의 이점 활용 (지속성, 지연 처리, 재시도)
- 시간이 지나도 쉽게 새 구독자 추가 가능

## 3. Fan Out 활용 사례 🛒

### 사례 1: 멀티 리전 메시지 배포

- 한 리전의 SNS 토픽에서 다른 리전의 SQS 대기열로 메시지 전송
- 글로벌 애플리케이션의 지역 간 이벤트 동기화
- 재해 복구 시나리오 지원

예시:
- 미국(오레곤) 리전에서 이벤트 발생 → SNS 토픽 발행
- 일본 리전, 독일 리전의 SQS가 그걸 **구독해서 자동 수신**
- **장점**: 재해 복구(한 리전 망가져도 다른 리전 처리 가능), 글로벌 동기화 가능

### 사례 2: S3 이벤트의 다중 처리

> S3에 객체 업로드 이벤트를 **여러 곳에서 동시에 처리**하고 싶을 때

![[스크린샷 2025-05-10 오후 4.16.12.png]]

**배경**:

- S3 이벤트 규칙에는 제한이 있음 (동일 이벤트 패턴에 대해 하나의 규칙만 가능)
- 하나의 S3 이벤트(예: 객체 생성)를 여러 처리기로 라우팅해야 함


**Fan Out 솔루션**:

1. S3 이벤트를 SNS 토픽으로 전송
2. 여러 SQS 대기열, Lambda 함수, 이메일 등이 토픽 구독
3. 하나의 이벤트가 여러 시스템에 동시 전달

### 사례 3: Kinesis Data Firehose를 통한 데이터 보관

> SNS로 들어온 메시지를 **자동으로 저장**하고 싶을 때

![[스크린샷 2025-05-10 오후 4.17.11.png]]
**특징**:

- SNS와 Kinesis Data Firehose 직접 통합
	- Kinesis Data Firehose : 실시간 또는 거의 실시간으로 데이터를 수집해서, 자동으로 저장소(S3, Redshift 등)에 보내주는 완전 관리형 서비스
- 메시지 데이터를 S3, Redshift, Elasticsearch 등에 저장
- 실시간 이벤트의 영구 보관 솔루션

## 4. FIFO 토픽의 Fan Out 패턴 🔢

### SNS FIFO 토픽의 특성

- 메시지 순서 보장 (First-In-First-Out)
- 메시지 그룹 ID에 따른 정렬
- 중복 제거 기능
- ==구독자는 SQS FIFO 대기열만 가능==
- 제한된 처리량 (SQS FIFO와 동일)

### 아키텍처

![[스크린샷 2025-05-10 오후 4.19.43.png]]

### 필요 사례

- 순서가 중요한 이벤트의 다중 처리 필요
- 정확히 한 번 처리 보장 필요
- 예: 금융 거래, 주문 처리, 재고 관리

## 5. SNS 메시지 필터링을 통한 선택적 Fan Out 🔍

### 메시지 필터링 정책 개념

- JSON 형식의 구독 속성 - 메시지 안의 JSON 데이터를 검사해서 필터링
- 수신할 메시지의 선택적 필터링 제공
- 필터링 정책이 없으면 모든 메시지 수신

### 아키텍처 구성

![[스크린샷 2025-05-10 오후 4.20.53.png]]

### 활용 이점

- 불필요한 메시지 처리 제거
- 특정 조건의 메시지만 처리
- 동일한 SNS 토픽에서 다양한 처리 패턴 구현
- 메시지 라우팅 로직을 애플리케이션 코드에서 인프라로 이동


# Amazon Kinesis Data Streams: 실시간 스트리밍 데이터의 처리 기술 🚀

## 1. Kinesis Data Streams 개요 🔍

Kinesis Data Streams는 실시간으로 스트리밍 데이터를 수집하고 저장하는 AWS 서비스입니다. **시험에서 중요한 키워드는 "실시간"** 이다.

### 1.1 실시간 데이터란?

실시간 데이터는 즉석에서 생성되고 즉시 사용되는 데이터를 말한다:

- 웹사이트 클릭스트림 (사용자 행동 데이터)
- IoT 디바이스 데이터 (인터넷 연결 자전거 등)
- 서버 메트릭과 로그

## 2. Kinesis Data Streams의 기본 구조 🧩

![[스크린샷 2025-05-10 오후 4.32.53.png]]

### 2.1 데이터 흐름 구조

```
실시간 데이터 → 프로듀서 → Kinesis Data Streams → 컨슈머
```

- **프로듀서**: 실시간으로 보내는 친구
    - 애플리케이션 코드
    - 웹사이트나 디바이스의 데이터 수집 코드
    - Kinesis 에이전트 (서버에 설치하여 메트릭/로그 수집)
- **컨슈머**:
    - 사용자 개발 애플리케이션
    - Lambda 함수
    - Amazon Data Firehose
    - Kinesis Data Analytics (Apache Flink)

## 3. Kinesis Data Streams 주요 기능 📊

- **데이터 보존**: 최대 365일까지 데이터 보관 가능
- **데이터 재처리**: 저장된 데이터는 컨슈머가 재처리 가능
- **데이터 불변성**: 한번 스트림에 전송된 데이터는 삭제할 수 없음 (만료될 때까지 유지)
- **데이터 크기**: 레코드당 최대 1MB까지 전송 가능
- **순서 보장**: 동일한 파티션 ID를 가진 데이터는 순서대로 정렬됨
- **보안 기능**: 미사용 데이터 암호화, KMS 암호화, HTTPS 암호화 지원

**핵심 포인트!** 💡 일반적인 사용 사례는 소규모 실시간 데이터를 대량으로 처리하는 것이다.

## 4. 개발 라이브러리 🛠️

- **Kinesis Producer Library (KPL)**: 높은 처리량을 위해 최적화된 프로듀서 애플리케이션 개발용
- **Kinesis Client Library (KCL)**: 최적화된 컨슈머 애플리케이션 개발용

Kinesis를 그냥 “쓰는 게 아니라” 내가 데이터를 보내는 쪽(Producer)이나
받아서 처리하는 쪽(Consumer)을 직접 코드로 개발할 때 사용하는 라이브러리이다.

## 5. 용량 모드 ⚙️

### 5.1 프로비저닝 모드 - "내가 샤드를 설계함"

- 스트림의 **샤드** 개수를 직접 선택
- 샤드 = 스트림의 기본 용량 단위
- 각 샤드 용량:
    - **인바운드**: 초당 1MB, 초당 1,000개 레코드
    - **아웃바운드**: 초당 2MB
- 필요에 따라 수동으로 샤드 수 조정 가능
- 비용: 프로비저닝된 각 샤드에 대해 시간당 요금 지불

샤드가 늘어날 수록 인바운드 처리량이 늘어난다.

**실무 팁!** 🌟 예를 들어, 초당 10,000개 레코드 또는 초당 10MB를 처리하려면 10개의 샤드가 필요하다

### 5.2 온디맨드 모드 - "자동으로 확장됨"

- Kinesis 데이터 스트림의 용량을 직접 관리할 필요 없음
- **기본 용량**: 초당 약 4MB 또는 404,000개 레코드
- 지난 30일간 관찰된 처리량에 따라 자동 확장
- 비용: 스트림당 시간당 기본 요금 + 데이터 입출력량에 따른 요금

**고급 팁!** 🧠 예측 불가능한 워크로드나 관리 오버헤드를 줄이고 싶은 경우 온디맨드 모드가 적합하다.

## 6. 요약: Kinesis Data Streams 핵심 포인트 📌

1. **실시간 데이터 처리**: 즉석에서 생성되는 데이터를 실시간으로 수집 및 저장
2. **프로듀서-컨슈머 모델**: 데이터 소스에서 스트림으로, 스트림에서 처리 애플리케이션으로
3. **장기 데이터 보존**: 최대 365일까지 데이터 유지 및 재처리 가능
4. **샤드 기반 확장성**: 샤드 단위로 용량 확장, 프로비저닝 또는 온디맨드 모드 선택 가능
5. **보안 및 데이터 순서 보장**: 암호화 기능과 파티션 ID 기반 순서 유지


# Amazon Data Firehose
## 1. Amazon Data Firehose 개요 🔍

Amazon Data Firehose는 소스에서 타깃 목적지로 데이터를 전송하는 AWS 서비스이다.

### **✅ 컨셉:**

> **“데이터를 알아서 받아서 자동으로 S3나 Redshift에 넣어줄게요”**

### 1.1 데이터 소스 옵션

Firehose로 데이터를 전송하는 방법은 다양하다:

- **직접 구현 소스**:
    - 애플리케이션, 클라이언트 (SDK 사용)
    - Kinesis 에이전트
- **AWS 서비스 연동**:
    - Kinesis Data Streams
    - Amazon CloudWatch 로그 및 이벤트
    - AWS IoT

## 2. Firehose 데이터 처리 흐름 🧩

![[스크린샷 2025-05-10 오후 10.03.31.png]]

```
데이터 소스 → Firehose → [선택적 Lambda 변환] → 버퍼링 → 목적지
```

### 2.1 선택적 데이터 변환

- Lambda 함수를 사용하여 데이터 변환 가능
- 데이터 형식 변환, 필터링, 보강 작업 수행

### 2.2 버퍼링 메커니즘

- 데이터가 버퍼에 쌓임
- 특정 조건(크기 또는 시간)에 도달하면 목적지로 플러시

## 3. Firehose 지원 목적지 🎯

### 3.1 AWS 목적지

- **Amazon S3**: 데이터 저장 및 분석용
- **Amazon Redshift**: 데이터 웨어하우징(데이터 분석을 위해 데이터를 저장하고 관리하는 중앙 저장소)
- **Amazon OpenSearch Service**: 검색 및 분석

### 3.2 서드파티 목적지

- **타사 파트너 연동**: Datadog, Splunk, New Relic, MongoDB
- **사용자 정의 HTTP 엔드포인트**: 지원되지 않는 목적지를 위한 옵션

### 3.3 백업 옵션

- 모든 데이터의 S3 백업 지원
- 또는 실패한 데이터만 S3에 백업 가능

## 4. Firehose 주요 특징 ⚙️

- **완전 관리형 서비스**: 인프라 관리 불필요
- **자동 확장**: 워크로드에 따라 자동으로 확장
- **서버리스**: 사용한 만큼만 비용 지불 <- 서버 운영을 사용자가 직접하지 않아도 된다. 그냥 스트림만 구성해주면 되는 것이다.
- **Near Real-Time**: 거의 실시간에 가까운 처리 
    - 버퍼링으로 인한 약간의 지연 발생 (기본적으로 활성화됨)
    - 버퍼는 크기 또는 시간 조건에 따라 플러시됨


## 5. Kinesis Data Streams vs Amazon Data Firehose 비교 🔄

| 특징         | Kinesis Data Streams | Amazon Data Firehose    |
| ---------- | -------------------- | ----------------------- |
| **목적**     | 스트리밍 데이터 수집 서비스      | 스트리밍 데이터를 목적지로 로드       |
| **코드 작성**  | 프로듀서 및 컨슈머 코드 필요     | 완전 관리형 (코드 작성 최소화)      |
| **처리 시간**  | 실시간                  | 거의 실시간 (Near Real-Time) |
| **용량 모드**  | 프로비저닝 모드와 온디맨드 모드    | 자동 확장                   |
| **데이터 저장** | 최대 1년까지 데이터 저장       | 데이터 저장 기능 없음            |
| **리플레이**   | 데이터 리플레이 기능 있음       | 리플레이 기능 없음              |

**핵심 포인트!** 💡 시험에서는 "Near Real-Time"이라는 키워드가 나오면 Amazon Data Firehose를 가리키는 것임을 기억하자. 반면 "실시간(Real-Time)"은 Kinesis Data Streams를 의미한다.

## 7. 요약: Amazon Data Firehose 핵심 포인트 📌

1. **데이터 전송 전문가**: 소스에서 목적지로 데이터를 효율적으로 전송
2. **다양한 소스와 목적지**: AWS 서비스부터 서드파티 솔루션까지 폭넓은 지원
3. **Near Real-Time 처리**: 버퍼링 메커니즘을 통한 준실시간 데이터 전송
4. **변환 능력**: 형식 변환, 압축, Lambda를 통한 사용자 정의 변환
5. **서버리스 아키텍처**: 관리 오버헤드 없이 자동 확장되는 완전 관리형 서비스

Amazon Data Firehose는 스트리밍 데이터를 다양한 목적지로 쉽게 전송하고 싶을 때 최적의 선택입니다! 🚀


![[스크린샷 2025-05-10 오후 10.08.56.png]]

| Feature          | SQS                                          | SNS                                    | Kinesis                                                                     |
| ---------------- | -------------------------------------------- | -------------------------------------- | --------------------------------------------------------------------------- |
| 데이터 처리 방식        | Consumer가 "pull" 방식으로 가져감                    | 데이터를 여러 구독자에게 "push"                   | Standard: pull / Enhanced fan-out: push                                     |
| 메시지 보존           | 소비 후 삭제됨                                     | 전달되지 않으면 유실됨 (지속되지 않음)                 | 데이터를 재생 가능 (replay)                                                         |
| 구독자 / 워커 수       | 원하는 만큼의 워커(consumer) 가능                      | 최대 12,500,000명 구독자                     | Enhanced fan-out 시: consumer당 2MB/s 처리 가능                                   |
| Throughput 사전 설정 | 필요 없음                                        | 필요 없음                                  | 사전 설정 (Provisioned) 또는 온디맨드 설정 가능                                           |
| 메시지 순서 보장        | FIFO 큐에서만 순서 보장                              | SQS FIFO와 연동 시 순서 보장 가능                | Shard 단위로 순서 보장                                                             |
| 지연 처리 기능         | 개별 메시지에 지연 설정 가능 (30초 등 일정시간 뒤에 대기열에 나타나도록 ) | 해당 없음                                  | 데이터 보존 기간 설정 가능 (1~365일 후 만료)                                               |
| 기타 특징            | 단순 큐 / 분산 처리용                                | Pub/Sub 구조, SQS와 함께 Fan-out 아키텍처 구성 가능 | 실시간 빅데이터 처리, ETL, 분석 용도에 적합                                                 |
| 처리 단위 (크기 제한)    | 제한 없음 (기본 256KB, 확장 가능)                      | 제한 명시 없음                               | 2MB/s per shard (Standard), 2MB/s per shard per consumer (Enhanced fan-out) |